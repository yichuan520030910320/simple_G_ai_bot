import gradio as gr
import json
import os
import time
from io import BytesIO
from PIL import Image

# å¯¼å…¥é¡¹ç›®çš„æ ¸å¿ƒé€»è¾‘å’Œé…ç½®
from geo_bot import GeoBot, AGENT_PROMPT_TEMPLATE
from benchmark import MapGuesserBenchmark
from config import MODELS_CONFIG, DATA_PATHS
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

# --- å…¨å±€è®¾ç½® ---
# ä»HF Secretså®‰å…¨åœ°è¯»å–APIå¯†é’¥
os.environ["OPENAI_API_KEY"] = os.environ.get("OPENAI_API_KEY", "")
os.environ["ANTHROPIC_API_KEY"] = os.environ.get("ANTHROPIC_API_KEY", "")
# os.environ['GOOGLE_API_KEY'] = os.environ.get("GOOGLE_API_KEY", "")

# åŠ è½½golden labelsæ•°æ®
try:
    with open(DATA_PATHS["golden_labels"], "r", encoding="utf-8") as f:
        GOLDEN_LABELS = json.load(f).get("samples", [])
except FileNotFoundError:
    print(f"è­¦å‘Š: æ•°æ®æ–‡ä»¶ '{DATA_PATHS['golden_labels']}' æœªæ‰¾åˆ°ã€‚")
    GOLDEN_LABELS = []


# --- æ ¸å¿ƒå¤„ç†å‡½æ•° (ä½¿ç”¨yieldå®ç°æµå¼æ›´æ–°) ---
def run_agent_process(
    model_choice, steps_per_sample, sample_index, progress=gr.Progress(track_tqdm=True)
):
    """
    è¿™ä¸ªå‡½æ•°æ˜¯æ•´ä¸ªåº”ç”¨çš„å¼•æ“ï¼Œå®ƒæ˜¯ä¸€ä¸ªç”Ÿæˆå™¨ (generator)ï¼Œä¼šé€æ­¥yieldæ›´æ–°ã€‚
    """
    # 1. åˆå§‹åŒ–ç¯å¢ƒ
    yield {
        status_text: "çŠ¶æ€: æ­£åœ¨åˆå§‹åŒ–æµè§ˆå™¨å’ŒAIæ¨¡å‹...",
        image_output: None,
        reasoning_output: "",
        action_output: "",
        result_output: "",
    }

    config = MODELS_CONFIG.get(model_choice)
    model_class = globals()[config["class"]]
    model_instance_name = config["model_name"]
    bot = GeoBot(model=model_class, model_name=model_instance_name, headless=True)

    # 2. åŠ è½½é€‰å®šçš„æ ·æœ¬ä½ç½®
    sample = GOLDEN_LABELS[sample_index]
    ground_truth = {"lat": sample.get("lat"), "lng": sample.get("lng")}

    if not bot.controller.load_location_from_data(sample):
        yield {status_text: "é”™è¯¯: åŠ è½½åœ°å›¾ä½ç½®å¤±è´¥ã€‚è¯·é‡è¯•ã€‚"}
        return

    bot.controller.setup_clean_environment()

    history = []
    final_guess = None

    # 3. å¼€å§‹å¤šæ­¥æ¢ç´¢å¾ªç¯
    for step in range(steps_per_sample):
        step_num = step + 1
        yield {status_text: f"çŠ¶æ€: æ¢ç´¢ä¸­... (ç¬¬ {step_num}/{steps_per_sample} æ­¥)"}

        # a. è§‚å¯Ÿ (Observe)
        bot.controller.label_arrows_on_screen()
        screenshot_bytes = bot.controller.take_street_view_screenshot()

        # b. æ€è€ƒ (Think)
        current_screenshot_b64 = bot.pil_to_base64(
            Image.open(BytesIO(screenshot_bytes))
        )
        history.append({"image_b64": current_screenshot_b64, "action": "N/A"})

        prompt = AGENT_PROMPT_TEMPLATE.format(
            remaining_steps=steps_per_sample - step,
            history_text="\n".join(
                [f"Step {j + 1}: {h['action']}" for j, h in enumerate(history)]
            ),
            available_actions=json.dumps(bot.controller.get_available_actions()),
        )
        message = bot._create_message_with_history(
            prompt, [h["image_b64"] for h in history]
        )
        response = bot.model.invoke(message)
        decision = bot._parse_agent_response(response)

        if not decision:
            decision = {
                "action_details": {"action": "PAN_RIGHT"},
                "reasoning": "Default recovery.",
            }

        action = decision.get("action_details", {}).get("action")
        reasoning = decision.get("reasoning", "N/A")
        history[-1]["action"] = action

        # c. æ›´æ–°UI
        yield {
            image_output: Image.open(BytesIO(screenshot_bytes)),
            reasoning_output: f"**AI Reasoning:**\n\n{reasoning}",
            action_output: f"**AI Action:** `{action}`",
        }

        # d. å¼ºåˆ¶åœ¨æœ€åä¸€æ­¥çŒœæµ‹
        if step_num == steps_per_sample and action != "GUESS":
            action = "GUESS"
            yield {status_text: "çŠ¶æ€: å·²è¾¾æœ€å¤§æ­¥æ•°ï¼Œå¼ºåˆ¶æ‰§è¡ŒGUESS..."}

        # e. è¡ŒåŠ¨ (Act)
        if action == "GUESS":
            lat, lon = (
                decision.get("action_details", {}).get("lat"),
                decision.get("action_details", {}).get("lon"),
            )
            if lat is not None and lon is not None:
                final_guess = (lat, lon)
            break
        elif action == "MOVE_FORWARD":
            bot.controller.move("forward")
        elif action == "MOVE_BACKWARD":
            bot.controller.move("backward")
        elif action == "PAN_LEFT":
            bot.controller.pan_view("left")
        elif action == "PAN_RIGHT":
            bot.controller.pan_view("right")

        time.sleep(1)  # æ­¥éª¤é—´ç¨ä½œåœé¡¿

    # 4. å¾ªç¯ç»“æŸï¼Œè®¡ç®—æœ€ç»ˆç»“æœå¹¶æ›´æ–°UI
    yield {status_text: "çŠ¶æ€: æ¢ç´¢å®Œæˆï¼Œæ­£åœ¨è®¡ç®—æœ€ç»ˆç»“æœ..."}

    if final_guess:
        distance = bot.calculate_distance(ground_truth, final_guess)
        result_text = f"""
        ### ğŸ“ æœ€ç»ˆç»“æœ
        - **çœŸå®ä½ç½®:** `Lat: {ground_truth["lat"]:.4f}, Lon: {ground_truth["lng"]:.4f}`
        - **AgentçŒœæµ‹:** `Lat: {final_guess[0]:.4f}, Lon: {final_guess[1]:.4f}`
        - **è·ç¦»è¯¯å·®:** `{distance:.1f} km`
        """
        yield {result_output: result_text, status_text: "çŠ¶æ€: å®Œæˆï¼"}
    else:
        yield {
            result_output: "### ğŸ“ æœ€ç»ˆç»“æœ\n\nAgent æœªèƒ½åšå‡ºæœ‰æ•ˆçŒœæµ‹ã€‚",
            status_text: "çŠ¶æ€: å®Œæˆï¼",
        }

    bot.close()  # å…³é—­æµè§ˆå™¨


# --- Gradio UI å¸ƒå±€ ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ—ºï¸ å¯è§†åŒ– GeoBot æ™ºèƒ½ä½“")
    gr.Markdown("é€‰æ‹©é…ç½®å¹¶å¯åŠ¨Agentï¼Œè§‚å¯Ÿå®ƒå¦‚ä½•é€šè¿‡æ¢ç´¢æ¥çŒœæµ‹è‡ªå·±çš„åœ°ç†ä½ç½®ã€‚")

    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("## âš™ï¸ æ§åˆ¶é¢æ¿")
            model_choice = gr.Dropdown(
                list(MODELS_CONFIG.keys()), label="é€‰æ‹©AIæ¨¡å‹", value="gpt-4o"
            )
            steps_per_sample = gr.Slider(
                3, 20, value=10, step=1, label="æ¯è½®æœ€å¤§æ¢ç´¢æ­¥æ•°"
            )
            sample_index = gr.Dropdown(
                [f"æ ·æœ¬ {i}" for i in range(len(GOLDEN_LABELS))],
                label="é€‰æ‹©æµ‹è¯•æ ·æœ¬",
                value="æ ·æœ¬ 0",
            )
            start_button = gr.Button("ğŸš€ å¯åŠ¨æ™ºèƒ½ä½“", variant="primary")
            status_text = gr.Markdown("çŠ¶æ€: ç­‰å¾…å¯åŠ¨")
            result_output = gr.Markdown()

        with gr.Column(scale=3):
            gr.Markdown("## ğŸ•µï¸ Agentæ¢ç´¢è¿‡ç¨‹")
            image_output = gr.Image(label="Agentå½“å‰è§†è§’", height=600)
            with gr.Row():
                reasoning_output = gr.Markdown(label="AI æ€è€ƒ")
                action_output = gr.Markdown(label="AI è¡ŒåŠ¨")

    # å°†æŒ‰é’®ç‚¹å‡»äº‹ä»¶è¿æ¥åˆ°æ ¸å¿ƒå‡½æ•°
    # `lambda s: int(s.split(' ')[1])` ç”¨äºä»"æ ·æœ¬ 0"ä¸­æå–å‡ºæ•°å­—0
    start_button.click(
        fn=run_agent_process,
        inputs=[model_choice, steps_per_sample, sample_index],
        outputs=[
            status_text,
            image_output,
            reasoning_output,
            action_output,
            result_output,
        ],
        # `js` å‚æ•°ç”¨äºåœ¨ç‚¹å‡»æŒ‰é’®åç¦ç”¨å®ƒï¼Œé˜²æ­¢é‡å¤ç‚¹å‡»
        js="""
        (model_choice, steps_per_sample, sample_index) => {
            return [
                "çŠ¶æ€: åˆå§‹åŒ–ä¸­...", 
                null, 
                "...", 
                "...", 
                ""
            ];
        }
        """,
    )

if __name__ == "__main__":
    demo.launch()
