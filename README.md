---
title: Omniscient
emoji: ğŸ‘ï¸â€ğŸ—¨ï¸
colorFrom: indigo
colorTo: purple
sdk: streamlit
python_version: 3.11
sdk_version: "1.35.0"
app_file: app.py
pinned: false
---

<div align="center">

# ğŸ§  Omniscient 
### *"The all-knowing AI that sees everything, knows everything"*

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.35.0-red.svg)](https://streamlit.io)
[![HuggingFace](https://img.shields.io/badge/ğŸ¤—%20HuggingFace-Space-yellow.svg)](https://huggingface.co/spaces/Omniscient001/Omniscient)

*A versatile AI bot for image analysis and dataset curation with support for multiple AI models*

ğŸ® **[Try it Live on HuggingFace!](https://huggingface.co/spaces/Omniscient001/Omniscient)** *(Actively WIP)*

</div>

---

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ—ƒï¸ **Dataset Curation**
Generate and curate high-quality image datasets with intelligent filtering and categorization.

### ğŸ” **Single Image Analysis** 
Benchmark different AI models on individual images with detailed performance metrics.

</td>
<td width="50%">

### ğŸ¤– **Agentic Analysis**
Multi-step AI reasoning and analysis with advanced decision-making capabilities.

### ğŸŒ **Multiple AI Providers**
Seamless integration with OpenAI, Anthropic, and Google AI platforms.

</td>
</tr>
</table>

---

## ğŸš€ Quick Start

### ğŸ“‹ **Step 1: Setup Environment**

```bash
cd simple_G_ai_bot
```

Create a `.env` file in the project root:

```bash
# ğŸ” .env
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here
GOOGLE_API_KEY=your_google_api_key_here
```

### ğŸ“¦ **Step 2: Install Dependencies**

```bash
uv sync
```

### ğŸ¯ **Step 3: Usage Examples**

<details>
<summary><b>ğŸ—ï¸ Dataset Curation</b></summary>

Generate 50 urban outdoor samples:
```bash
python main.py --mode data --samples 50 --urban --no-indoor
```

</details>

<details>
<summary><b>âš¡ Single Image Analysis</b></summary>

Benchmark GPT-4o on 5 samples:
```bash
python main.py --mode benchmark --models gpt-4o --samples 5
```

</details>

<details>
<summary><b>ğŸ§  Agentic Analysis</b></summary>

Run multi-step analysis with Gemini:
```bash
python main.py --mode agent --model gemini-2.5-pro --steps 10 --samples 5
```

</details>

---

## âš™ï¸ Configuration

### ğŸ”‘ **Environment Variables**

| Variable | Description | Status |
|:---------|:------------|:------:|
| `OPENAI_API_KEY` | OpenAI API key for GPT models | ğŸ”¶ Optional |
| `ANTHROPIC_API_KEY` | Anthropic API key for Claude models | ğŸ”¶ Optional |
| `GOOGLE_API_KEY` | Google AI API key for Gemini models | ğŸ”¶ Optional |

### ğŸ› ï¸ **Command Line Options**

#### ğŸŒŸ **Common Options**
- `--mode` â†’ Operation mode (`data`, `benchmark`, `agent`)
- `--samples` â†’ Number of samples to process *(default: 10)*

#### ğŸ™ï¸ **Data Mode Options**  
- `--urban` â†’ Focus on urban environments
- `--no-indoor` â†’ Exclude indoor scenes

#### ğŸ“Š **Benchmark Mode Options**
- `--models` â†’ AI model to use *(e.g., `gpt-4o`, `claude-3`, `gemini-pro`)*

#### ğŸ¤– **Agent Mode Options**
- `--model` â†’ AI model for agentic analysis  
- `--steps` â†’ Number of reasoning steps *(default: 5)*

---

## ğŸ¯ Supported Models

<div align="center">

| Provider | Models | Status |
|:--------:|:-------|:------:|
| **ğŸ”µ OpenAI** | GPT-4o, GPT-4, GPT-3.5-turbo | âœ… Active |
| **ğŸŸ£ Anthropic** | Claude-3-opus, Claude-3-sonnet, Claude-3-haiku | âœ… Active |
| **ğŸ”´ Google** | Gemini-2.5-pro, Gemini-pro, Gemini-pro-vision | âœ… Active |

</div>

---

## ğŸ“‹ Requirements

> **Prerequisites:**
> - ğŸ Python 3.8+
> - ğŸ“¦ UV package manager  
> - ğŸ”‘ Valid API keys for desired AI providers

---

## ğŸ”§ Installation

<table>
<tr>
<td>

**1ï¸âƒ£** Clone the repository
```bash
git clone <repository-url>
```

**2ï¸âƒ£** Navigate to project directory
```bash
cd simple_G_ai_bot
```

</td>
<td>

**3ï¸âƒ£** Create `.env` file with your API keys
```bash
touch .env
# Add your API keys
```

**4ï¸âƒ£** Install dependencies
```bash
uv sync
```

</td>
</tr>
</table>

**5ï¸âƒ£** Run the bot with desired mode and options! ğŸ‰

---

## ğŸ’¡ Examples

### ğŸ—ï¸ **Basic Dataset Generation**
```bash
python main.py --mode data --samples 20
```

### ğŸŒ† **Urban Scene Analysis**  
```bash
python main.py --mode data --samples 30 --urban --no-indoor
```

### âš”ï¸ **Model Comparison**
```bash
# GPT-4o Analysis
python main.py --mode benchmark --models gpt-4o --samples 10

# Claude-3 Analysis  
python main.py --mode benchmark --models claude-3-opus --samples 10
```

### ğŸ§  **Advanced Agentic Workflow**
```bash
python main.py --mode agent --model gemini-2.5-pro --steps 15 --samples 3
```

---

## ğŸ” Security Note

> âš ï¸ **Important**: Never commit your `.env` file to version control. Add `.env` to your `.gitignore` file to keep your API keys secure.

---

<div align="center">

## ğŸ“œ License

**MIT License** - see [LICENSE](LICENSE) file for details.

---

<img src="https://img.shields.io/badge/Made%20with-â¤ï¸-red.svg" alt="Made with love">
<img src="https://img.shields.io/badge/AI%20Powered-ğŸ¤–-blue.svg" alt="AI Powered">
<img src="https://img.shields.io/badge/Open%20Source-ğŸ’š-green.svg" alt="Open Source">

**â­ Star this repo if you find it useful!**

</div>